# UNRDF - Autonomic Knowledge Graph System

**Autonomous RDF knowledge graph system with MAPEK autonomic loops and reactive Knowledge Hooks**

UNRDF transforms static knowledge graphs into intelligent, self-managing systems through the **MAPEK autonomic loop** (Monitor-Analyze-Plan-Execute-Knowledge) and **Knowledge Hooks**‚Äîdeclarative, policy-driven triggers that react to graph changes in real-time.

```json
{
  "@context": {
    "@vocab": "urn:unrdf:manifest:",
    "unrdf": "urn:unrdf:",
    "cap": "urn:unrdf:capability:",
    "proto": "urn:unrdf:protocol:"
  },
  "@id": "urn:unrdf:v4.0.0",
  "@type": "SystemManifest",
  "name": "UNRDF v4.0.0",
  "version": "4.0.0",
  "purpose": "Autonomous RDF knowledge graph system for distributed intelligence",
  "capabilities": [
    "cap:knowledge-hooks",
    "cap:mapek-autonomic-loop",
    "cap:sparql-1.1",
    "cap:shacl-validation",
    "cap:cryptographic-provenance",
    "cap:opentelemetry-observability"
  ],
  "entrypoints": {
    "main": "./src/index.mjs",
    "knowledge-engine": "./src/knowledge-engine/index.mjs",
    "react-hooks": "./src/react-hooks/index.mjs",
    "cli": "./src/cli/index.mjs",
    "project-engine": "./src/project-engine/index.mjs"
  }
}
```

---

## Quick Start

```bash
# Install
pnpm add unrdf

# Initialize project structure
npx unrdf init

# Backup RDF store
npx unrdf store backup ./my-store --output backup.tar.gz

# Restore from backup
npx unrdf store restore backup.tar.gz --target ./restored-store

# Import RDF files
npx unrdf store import data/*.ttl --storePath ./my-store
```

```javascript
// Create a knowledge hook
import { defineHook, createDarkMatterCore } from 'unrdf';

const system = await createDarkMatterCore();
const hook = defineHook({
  meta: { name: 'person-name-required' },
  when: {
    kind: 'sparql-ask',
    query: `
      PREFIX foaf: <http://xmlns.com/foaf/0.1/>
      ASK {
        ?person a foaf:Person .
        FILTER NOT EXISTS { ?person foaf:name ?name }
      }
    `
  },
  run: async (event) => {
    if (event.result === true) {
      throw new Error('All persons must have a name');
    }
  }
});

await system.registerHook(hook);
```

---

# Documentation Structure (Diataxis Framework)

This documentation follows the [Diataxis framework](https://diataxis.fr/) with four distinct types:

- **[Tutorials](#tutorials)** - Step-by-step learning guides
- **[How-To Guides](#how-to-guides)** - Task-focused problem solving
- **[Reference](#reference)** - Complete technical specifications
- **[Explanation](#explanation)** - Deep conceptual understanding

---

## Tutorials

*Learning-oriented guides that teach you how to use MAPEK and Knowledge Hooks*

### Tutorial 1: Your First Knowledge Hook

Learn how to create a reactive hook that enforces data quality rules.

**Step 1: Set up the system**

```javascript
import { createDarkMatterCore, defineHook } from 'unrdf';

const system = await createDarkMatterCore();
```

**Step 2: Define a hook**

```javascript
const validationHook = defineHook({
  meta: {
    name: 'person-name-required',
    description: 'Ensures all persons have names'
  },
  when: {
    kind: 'sparql-ask',
    query: `
      PREFIX foaf: <http://xmlns.com/foaf/0.1/>
      ASK {
        ?person a foaf:Person .
        FILTER NOT EXISTS { ?person foaf:name ?name }
      }
    `
  },
  run: async (event) => {
    if (event.result === true) {
      throw new Error('CONSTRAINT_VIOLATION: All persons must have names');
    }
    return { validated: true };
  }
});
```

**Step 3: Register the hook**

```javascript
await system.registerHook(validationHook);
```

**Step 4: Execute a transaction**

```javascript
// This will trigger the hook
const receipt = await system.executeTransaction({
  additions: [
    { subject: 'ex:alice', predicate: 'rdf:type', object: 'foaf:Person' }
    // Missing foaf:name - hook will reject this
  ]
});
```

**Result:** The transaction is rejected because the hook detected a person without a name.

### Tutorial 2: Running Your First MAPEK Cycle

Learn how to use the MAPEK autonomic loop to continuously monitor and improve your system.

**Step 1: Initialize project model**

```javascript
import { runMapekIteration, reportMapekStatus } from 'unrdf/project-engine';
import { buildProjectModelFromFs, inferDomainModel } from 'unrdf/project-engine';

// Build RDF models from your codebase
const projectStore = await buildProjectModelFromFs('/path/to/project');
const domainStore = await inferDomainModel(projectStore);
```

**Step 2: Run one MAPEK iteration**

```javascript
const result = await runMapekIteration({
  projectStore,
  domainStore,
  projectRoot: '/path/to/project',
  stackProfile: { webFramework: 'next' }
});
```

**Step 3: View the status**

```javascript
console.log(reportMapekStatus(result));

// Output:
// ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
// ‚ïë         AUTONOMIC SYSTEM STATUS        ‚ïë
// ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
// 
// üîÑ Overall Health: 85%
// 
// üìä Metrics:
//    Gap Score: 30/100
//    Type Score: 0/100
//    Hotspot Score: 15/100
//    Drift: minor
// 
// üìã Decisions:
//    ‚öôÔ∏è  Generate missing UserAPI
```

**Step 4: Enable continuous monitoring**

```javascript
import { runContinuousMapekLoop } from 'unrdf/project-engine';

const result = await runContinuousMapekLoop({
  getState: async () => ({
    projectStore: await buildProjectModelFromFs('/path'),
    domainStore: await inferDomainModel(projectStore),
    projectRoot: '/path'
  }),
  applyActions: async (actions) => {
    // Auto-fix issues
    for (const action of actions) {
      if (action.type === 'generate-files') {
        await generateMissingFiles(action);
      }
    }
  },
  intervalMs: 5000,
  maxIterations: 10
});

console.log(`System converged after ${result.iterations} iterations`);
```

### Tutorial 3: Integrating MAPEK with Knowledge Hooks

Learn how MAPEK's Execute phase creates and registers Knowledge Hooks automatically.

**Step 1: Run MAPEK to detect issues**

```javascript
const mapekResult = await runMapekIteration({
  projectStore,
  domainStore,
  projectRoot: '/path'
});
```

**Step 2: Create autonomic hooks from findings**

```javascript
import { createAutonomicHooks } from 'unrdf/project-engine';

const hooks = createAutonomicHooks(mapekResult, projectStore);

// Hooks are automatically created for:
// - Missing files (autonomic:auto-generate-missing-files)
// - Type mismatches (autonomic:auto-sync-types)
// - High-risk hotspots (autonomic:hotspot-alert)
```

**Step 3: Register hooks with the system**

```javascript
for (const hook of hooks) {
  await system.registerHook(hook);
}
```

**Step 4: Hooks now monitor and auto-fix**

The registered hooks will automatically:
- Detect when new entities are added without corresponding files
- Alert on type mismatches
- Warn about high-complexity features

---

## How-To Guides

*Task-focused instructions for solving specific problems*

### How-To: Enforce Data Quality with Hooks

**Problem:** You need to ensure all entities in your graph meet certain quality criteria.

**Solution:** Create validation hooks that run before transactions commit.

```javascript
import { defineHook, createDarkMatterCore } from 'unrdf';

const system = await createDarkMatterCore();

// Hook 1: Require email format
const emailHook = defineHook({
  meta: { name: 'email-format-validation' },
  channel: { view: 'before' }, // Run before transaction commits
  when: {
    kind: 'sparql-ask',
    query: `
      ASK {
        ?entity ex:email ?email .
        FILTER (!REGEX(?email, "^[^@]+@[^@]+\\.[^@]+$"))
      }
    `
  },
  run: async (event) => {
    if (event.result === true) {
      throw new Error('Invalid email format detected');
    }
  }
});

// Hook 2: Require age to be positive
const ageHook = defineHook({
  meta: { name: 'age-validation' },
  channel: { view: 'before' },
  when: {
    kind: 'sparql-ask',
    query: 'ASK { ?person ex:age ?age . FILTER (?age < 0 || ?age > 150) }'
  },
  run: async (event) => {
    if (event.result) {
      throw new Error('Age must be between 0 and 150');
    }
  }
});

await system.registerHook(emailHook);
await system.registerHook(ageHook);
```

### How-To: Monitor System Health with MAPEK

**Problem:** You want to continuously monitor your codebase for gaps, type issues, and complexity.

**Solution:** Set up a continuous MAPEK loop.

```javascript
import { runContinuousMapekLoop } from 'unrdf/project-engine';

const loop = await runContinuousMapekLoop({
  getState: async () => {
    const projectStore = await buildProjectModelFromFs(process.cwd());
    const domainStore = await inferDomainModel(projectStore);
    return { projectStore, domainStore, projectRoot: process.cwd() };
  },
  applyActions: async (actions) => {
    console.log(`Applying ${actions.length} auto-fixes...`);
    // Implement your auto-fix logic here
  },
  intervalMs: 10000, // Check every 10 seconds
  maxIterations: 20
});

if (loop.converged) {
  console.log(`‚úÖ System healthy (${loop.finalHealth}% health)`);
} else {
  console.log(`‚ö†Ô∏è  System needs attention (${loop.finalHealth}% health)`);
}
```

### How-To: Auto-Fix Missing Files with MAPEK

**Problem:** Your domain model defines entities, but corresponding files (APIs, components, tests) are missing.

**Solution:** Use MAPEK to detect gaps and auto-generate files.

```javascript
import { runMapekIteration } from 'unrdf/project-engine';

const result = await runMapekIteration({
  projectStore,
  domainStore,
  projectRoot: '/path'
});

// Filter for gap-fixing decisions
const gapDecisions = result.decisions.filter(d => d.issue === 'missing-roles');

for (const decision of gapDecisions) {
  for (const target of decision.targets) {
    // Generate missing files
    const plan = await planMaterialization(projectStore, templateGraph, {
      entities: [target.entity],
      roles: target.roles // e.g., ['Api', 'Component', 'Test']
    });
    await applyMaterializationPlan(plan);
  }
}
```

### How-To: Create Content-Addressed Hook Conditions

**Problem:** You want hook conditions to be verifiable, shareable artifacts, not inline strings.

**Solution:** Use content-addressed file references.

```javascript
import { defineHook } from 'unrdf';
import { createHash } from 'crypto';
import { readFileSync } from 'fs';

// Store condition in a file
const conditionFile = './hooks/compliance/large-transaction.ask.rq';
const conditionContent = readFileSync(conditionFile, 'utf-8');
const conditionHash = createHash('sha256').update(conditionContent).digest('hex');

const hook = defineHook({
  meta: { name: 'large-transaction-monitor' },
  when: {
    kind: 'sparql-ask',
    ref: {
      uri: `file://${conditionFile}`,
      sha256: conditionHash,
      mediaType: 'application/sparql-query'
    }
  },
  run: async (event) => {
    if (event.result === true) {
      console.warn('Large transaction detected!');
    }
  }
});
```

### How-To: Debug Hook Execution

**Problem:** A hook isn't triggering when expected, or you need to trace execution.

**Solution:** Use OpenTelemetry spans and SPARQL queries.

```javascript
// Query hook execution traces
const traces = await system.query({
  query: `
    PREFIX otel: <urn:opentelemetry:>
    PREFIX unrdf: <urn:unrdf:>
    
    SELECT ?traceId ?spanName ?duration ?status WHERE {
      ?span a otel:Span ;
            otel:traceId ?traceId ;
            otel:name ?spanName ;
            otel:duration ?duration ;
            otel:status ?status .
      FILTER(STRSTARTS(?spanName, "unrdf.hook."))
    }
    ORDER BY DESC(?duration)
    LIMIT 100
  `,
  type: 'sparql-select'
});

console.table(traces);
```

---

## Reference

*Complete technical specifications and API documentation*

### MAPEK API Reference

#### `runMapekIteration(options)`

Runs a single MAPEK cycle (Monitor ‚Üí Analyze ‚Üí Plan ‚Üí Execute ‚Üí Knowledge).

**Parameters:**

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `projectStore` | N3 Store | ‚úÖ | RDF project structure from filesystem |
| `domainStore` | N3 Store | ‚úÖ | RDF domain model (entities, fields, relationships) |
| `projectRoot` | string | ‚úÖ | Filesystem root path |
| `stackProfile` | object | ‚ùå | Framework detection result (e.g., `{ webFramework: 'next' }`) |
| `baselineSnapshot` | Store | ‚ùå | Baseline snapshot for drift detection |
| `knowledge` | object | ‚ùå | Learned patterns from previous runs |

**Returns:**

```javascript
{
  state: {
    phase: 'monitor' | 'analyze' | 'plan' | 'execute' | 'knowledge',
    timestamp: string, // ISO 8601
    findings: {
      gaps: { gaps: Array<GapFinding> },
      typeIssues: { mismatches: Array<TypeMismatch> },
      hotspots: { hotspots: Array<Hotspot>, topRisks: Array<Risk> },
      drift: { driftSeverity: 'none' | 'minor' | 'major' }
    },
    metrics: {
      gapScore: number, // 0-100
      typeScore: number, // 0-100
      hotspotScore: number, // 0-100
      driftSeverity: string
    },
    decisions: Array<Decision>,
    actions: Array<Action>
  },
  overallHealth: number, // 0-100
  phase: string,
  findings: object,
  metrics: object,
  decisions: Array<object>,
  actions: Array<object>,
  learnings: object,
  shouldRepeat: boolean
}
```

**Example:**

```javascript
import { runMapekIteration } from 'unrdf/project-engine';

const result = await runMapekIteration({
  projectStore: myProjectStore,
  domainStore: myDomainStore,
  projectRoot: '/path/to/project'
});

console.log(`Health: ${result.overallHealth}%`);
console.log(`Decisions: ${result.decisions.length}`);
```

#### `runContinuousMapekLoop(options)`

Runs MAPEK repeatedly until system converges or max iterations reached.

**Parameters:**

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `getState` | Function | ‚úÖ | Async function returning `{ projectStore, domainStore, projectRoot }` |
| `applyActions` | Function | ‚úÖ | Async function to apply auto-fixable actions |
| `intervalMs` | number | ‚ùå | Polling interval in milliseconds (default: 5000) |
| `maxIterations` | number | ‚ùå | Maximum iterations before stopping (default: 10) |

**Returns:**

```javascript
{
  converged: boolean,
  iterations: number,
  finalHealth: number, // 0-100
  finalState: object
}
```

#### `createAutonomicHooks(mapekFindings, projectStore)`

Creates Knowledge Hooks from MAPEK findings for autonomous execution.

**Parameters:**

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `mapekFindings` | object | ‚úÖ | Result from `runMapekIteration` |
| `projectStore` | Store | ‚úÖ | Project RDF store |

**Returns:** `Array<Hook>` - Array of hook definitions ready for registration

**Generated Hooks:**

- `autonomic:auto-generate-missing-files` - Triggers on gap detection
- `autonomic:auto-sync-types` - Triggers on type mismatch
- `autonomic:hotspot-alert` - Alerts on high-risk features

### Knowledge Hooks API Reference

#### `defineHook(spec)`

Creates a new Knowledge Hook with validation.

**Parameters:**

```javascript
{
  meta: {
    name: string, // Required: unique hook identifier
    description?: string,
    version?: string,
    tags?: string[]
  },
  channel?: {
    graphs?: string[], // Named graphs to observe
    view?: 'before' | 'after' | 'delta' // Graph state view
  },
  when: {
    kind: 'sparql-ask' | 'sparql-select' | 'shacl',
    query?: string, // SPARQL query string
    ref?: { // Content-addressed reference (preferred)
      uri: string,
      sha256: string,
      mediaType: string
    }
  },
  before?: (event: HookEvent) => Promise<HookPayload | {cancel: true, reason?: string}>,
  run: (event: HookEvent) => Promise<HookResult>,
  after?: (event: HookEvent & {result: any}) => Promise<HookResult>,
  determinism?: { seed?: number },
  receipt?: { anchor?: 'git-notes' | 'none' }
}
```

**Returns:** `Hook` - Validated hook definition

**Example:**

```javascript
import { defineHook } from 'unrdf';

const hook = defineHook({
  meta: { name: 'my-hook' },
  when: {
    kind: 'sparql-ask',
    query: 'ASK { ?s ?p ?o }'
  },
  run: async (event) => {
    return { result: 'success' };
  }
});
```

#### `KnowledgeHookManager`

Manages hook registration, evaluation, and execution.

**Methods:**

- `registerHook(hook: Hook): Promise<void>` - Register a hook
- `removeHook(name: string): Promise<void>` - Remove a hook
- `executeKnowledgeHook(name: string, event: object, options?: object): Promise<object>` - Execute a specific hook
- `executeAllHooks(event: object, options?: object): Promise<Array<object>>` - Execute all matching hooks

**Example:**

```javascript
import { KnowledgeHookManager, createDarkMatterCore } from 'unrdf';

const system = await createDarkMatterCore();
const manager = system.getComponent('knowledgeHookManager');

await manager.registerHook(myHook);
const result = await manager.executeKnowledgeHook('my-hook', {
  payload: { delta: myDelta },
  context: { graph: myStore }
});
```

### Hook Lifecycle

Hooks execute in three phases:

1. **`before`** - Pre-condition gate, can cancel execution
2. **`run`** - Core effect execution
3. **`after`** - Post-execution cleanup/auditing

```javascript
const hook = defineHook({
  meta: { name: 'lifecycle-example' },
  when: { kind: 'sparql-ask', query: 'ASK { ?s ?p ?o }' },
  before: async (event) => {
    // Can modify payload or cancel
    if (shouldCancel) {
      return { cancel: true, reason: 'Cancelled by before phase' };
    }
    return { ...event.payload, normalized: true };
  },
  run: async (event) => {
    // Main execution
    return { result: 'executed' };
  },
  after: async (event) => {
    // Cleanup, logging, auditing
    console.log(`Hook completed: ${event.result}`);
    return {};
  }
});
```

### Condition Types

**SPARQL ASK:** Boolean condition (true/false)

```javascript
when: {
  kind: 'sparql-ask',
  query: 'ASK { ?person ex:age ?age . FILTER (?age < 0) }'
}
```

**SPARQL SELECT:** Returns bindings, hook runs if results exist

```javascript
when: {
  kind: 'sparql-select',
  query: 'SELECT ?person WHERE { ?person ex:status "inactive" }'
}
```

**SHACL:** Shape-based validation

```javascript
when: {
  kind: 'shacl',
  ref: {
    uri: 'file://shapes/person-shape.ttl',
    sha256: '...',
    mediaType: 'text/turtle'
  }
}
```

### Transaction Integration

Hooks execute automatically during transactions:

```javascript
const receipt = await system.executeTransaction({
  additions: [
    { subject: 'ex:alice', predicate: 'rdf:type', object: 'foaf:Person' }
  ]
});

// Hooks with channel.view='before' run before commit
// Hooks with channel.view='after' run after commit
// Hooks with channel.view='delta' run on delta only
```

### Performance SLOs

| Metric | Target | Unit |
|--------|--------|------|
| Hook registration | p99 < 1ms | milliseconds |
| Condition evaluation | p99 < 2ms | milliseconds |
| Hook execution | p99 < 10ms | milliseconds |
| Full pipeline | p99 < 50ms | milliseconds |
| Hook throughput | 10,000/min | executions per minute |

---

## Explanation

*Deep conceptual understanding of MAPEK and Knowledge Hooks*

### What is MAPEK?

**MAPEK** stands for **Monitor-Analyze-Plan-Execute-Knowledge**‚Äîa closed-loop autonomic system that continuously:

1. **Monitors** - Observes system state (gaps, type issues, complexity, drift)
2. **Analyzes** - Interprets findings and calculates health scores
3. **Plans** - Decides what actions to take (auto-fixable vs. manual)
4. **Executes** - Applies fixes through Knowledge Hooks
5. **Learns** - Extracts patterns to improve future decisions

**Why MAPEK Matters:**

Traditional systems require manual intervention to maintain quality. MAPEK automates this through continuous monitoring and autonomous execution via Knowledge Hooks.

| Traditional Approach | MAPEK Approach |
|---------------------|----------------|
| Manual code reviews | Automatic gap detection |
| Type errors in production | Real-time type validation |
| Refactoring fear | Safe, planned, auto-tracked |
| Code decay over time | Continuous drift detection |
| Best practices as guidelines | Best practices as enforced hooks |

### The Five MAPEK Phases

#### Phase 1: Monitor

**Purpose:** Continuously observe system state

**Tools:**
- **Gap Finder** - Detects missing roles (APIs, components, tests) for entities
- **Type Auditor** - Validates Zod schemas match TypeScript types
- **Hotspot Analyzer** - Identifies high-complexity features
- **Drift Detector** - Tracks divergence from baseline model

**Output:** Raw findings (gaps, type mismatches, hotspots, drift)

#### Phase 2: Analyze

**Purpose:** Interpret findings and calculate health metrics

**Metrics:**
- **Gap Score (0-100)** - Missing critical functionality (higher = worse)
- **Type Score (0-100)** - Dangerous type mismatches (higher = worse)
- **Hotspot Score (0-100)** - Code complexity risk (higher = worse)
- **Overall Health** - Weighted average: `(gapScore * 0.3 + typeScore * 0.3 + hotspotScore * 0.2 + driftPenalty * 0.2) / 100`

**Output:** Health scores and prioritized issues

#### Phase 3: Plan

**Purpose:** Decide what actions to take

**Decision Types:**
- **Auto-fixable** - Can be executed automatically (e.g., generate missing files, sync types)
- **Manual review** - Requires human decision (e.g., refactor high-complexity features)

**Prioritization:** Type issues > gaps > complexity

**Output:** Array of decisions with `autoFixable` flags

#### Phase 4: Execute

**Purpose:** Apply auto-fixable decisions

**Execution Methods:**
- **Knowledge Hooks** - Reactive triggers that auto-fix issues
- **File Generation** - Create missing APIs, components, tests
- **Type Synchronization** - Sync Zod schemas with TypeScript
- **Refactoring Queue** - Queue recommendations for manual review

**Integration:** MAPEK creates Knowledge Hooks via `createAutonomicHooks()`, which are then registered and executed automatically.

**Output:** Applied actions and execution receipts

#### Phase 5: Knowledge

**Purpose:** Learn patterns from the cycle

**Learning Types:**
- **Gap Patterns** - Which entities consistently lack certain roles?
- **Type Patterns** - Which fields are frequently mismatched?
- **Hotspot Thresholds** - When does complexity become critical?
- **Policy Updates** - Update thresholds based on successful fixes

**Output:** Learned patterns stored for next iteration

### What are Knowledge Hooks?

**Knowledge Hooks** are declarative, policy-driven triggers that react to RDF graph changes. They transform passive knowledge graphs into reactive, self-governing systems.

**Key Characteristics:**

1. **Declarative Conditions** - Use SPARQL or SHACL to express *what* to monitor, not *how*
2. **Content-Addressed** - Conditions are identified by hash, enabling verification and deduplication
3. **Lifecycle Phases** - `before`, `run`, `after` provide complete execution control
4. **Cryptographic Provenance** - Every execution creates a signed receipt
5. **Transaction Integration** - Execute automatically during ACID transactions

**Why Knowledge Hooks Matter:**

Traditional RDF systems are **passive**‚Äîthey store data and answer queries, but don't proactively enforce rules or react to changes. Knowledge Hooks make RDF **reactive**:

- **Data Quality Enforcement** - Automatically reject invalid data
- **Business Rule Automation** - Encode policies as hooks
- **Real-Time Reactivity** - Respond to graph changes immediately
- **Self-Healing** - Auto-fix issues detected by MAPEK

### How MAPEK and Knowledge Hooks Work Together

**The Integration Flow:**

```
1. MAPEK Monitor Phase
   ‚Üì
   Detects gaps, type issues, hotspots
   ‚Üì
2. MAPEK Analyze Phase
   ‚Üì
   Calculates health scores, prioritizes issues
   ‚Üì
3. MAPEK Plan Phase
   ‚Üì
   Decides which issues are auto-fixable
   ‚Üì
4. MAPEK Execute Phase
   ‚Üì
   Creates Knowledge Hooks via createAutonomicHooks()
   ‚Üì
5. Knowledge Hooks Registered
   ‚Üì
   Hooks monitor graph for conditions
   ‚Üì
6. Hooks Execute on Graph Changes
   ‚Üì
   Auto-fix issues (generate files, sync types, alert)
   ‚Üì
7. MAPEK Knowledge Phase
   ‚Üì
   Learns from hook executions, updates policies
```

**Example: Auto-Generating Missing Files**

1. **MAPEK detects:** Entity `User` exists in domain model but lacks `Api` role
2. **MAPEK plans:** Decision to generate `UserAPI` file (auto-fixable)
3. **MAPEK executes:** Creates hook `autonomic:auto-generate-missing-files`
4. **Hook registered:** Hook monitors for new entities without APIs
5. **Graph changes:** New entity added without API
6. **Hook triggers:** Generates missing API file automatically
7. **MAPEK learns:** Pattern: "Entities in domain model always need APIs"

### Content-Addressed Conditions

**Why Content-Addressed?**

Hook conditions should be **verifiable artifacts**, not inline strings. Content-addressing enables:

- **Verification** - Same condition = same hash = can verify integrity
- **Deduplication** - Multiple hooks can reference the same condition
- **Provenance** - Conditions are standalone, auditable artifacts
- **Sharing** - Conditions can be shared across systems

**Best Practice:**

```javascript
// ‚ùå Bad: Inline query
when: {
  kind: 'sparql-ask',
  query: 'ASK { ?s ?p ?o }' // Not verifiable, not shareable
}

// ‚úÖ Good: Content-addressed reference
when: {
  kind: 'sparql-ask',
  ref: {
    uri: 'file://hooks/compliance/large-tx.ask.rq',
    sha256: 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855',
    mediaType: 'application/sparql-query'
  }
}
```

### Transaction Lifecycle with Hooks

**State Machine:**

```
PENDING ‚Üí ACTIVE ‚Üí HOOKS_PASSED ‚Üí APPLYING ‚Üí POST_HOOKS ‚Üí COMMITTED
           ‚Üì                              ‚Üì
        ROLLING_BACK ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì
      ROLLED_BACK
```

**Hook Execution Points:**

- **`before` hooks** - Run in `ACTIVE` state, can veto transaction
- **`after` hooks** - Run in `POST_HOOKS` state, for auditing/cleanup
- **`delta` hooks** - Run on delta graph (additions/removals only)

**Example:**

```javascript
// Transaction with hooks
const receipt = await system.executeTransaction({
  additions: [
    { subject: 'ex:alice', predicate: 'rdf:type', object: 'foaf:Person' }
  ]
});

// Execution flow:
// 1. State: PENDING ‚Üí ACTIVE
// 2. Run 'before' hooks (can cancel here)
// 3. State: ACTIVE ‚Üí HOOKS_PASSED (if all pass)
// 4. Apply delta to graph
// 5. State: HOOKS_PASSED ‚Üí APPLYING ‚Üí POST_HOOKS
// 6. Run 'after' hooks
// 7. State: POST_HOOKS ‚Üí COMMITTED
```

### Autonomic Properties

UNRDF achieves autonomic computing properties through MAPEK + Knowledge Hooks:

| Property | Maturity | How It Works |
|----------|----------|--------------|
| **Self-Configuration** | 0.92 | Policy packs auto-apply, hooks auto-register |
| **Self-Healing** | 0.87 | MAPEK detects issues, hooks auto-fix |
| **Self-Optimization** | 0.78 | Query optimization, resource allocation |
| **Self-Protection** | 0.95 | Lockchain provides cryptographic audit trail |

**Maturity Score:** Weighted average of autonomic properties (0-1 scale)

### The 80/20 Principle

UNRDF follows the **80/20 rule** (Pareto Principle):

- **20% of components** deliver 80% of value ‚Üí Focus on Tier 1 capabilities
- **20% of queries** take 80% of time ‚Üí Optimize critical path
- **20% of code paths** handle 80% of use cases ‚Üí Implement those first

**Tier System:**

- **Tier 1 (60% usage):** `defineHook`, `executeTransaction`, `query` - Use these first
- **Tier 2 (20% usage):** `registerHook`, `reason`, `canonicalize` - Specialized operations
- **Tier 3 (15% usage):** `ResolutionLayer`, `PolicyPackManager` - Advanced features
- **Tier 4 (5% usage):** `FederatedQuery`, `StreamProcessor` - Experimental

---

## Installation

```bash
# Install from npm
pnpm add unrdf

# Verify installation
node -e "import('unrdf').then(m => console.log('Version:', m.default?.version || '4.0.0'))"
```

## CLI Commands

UNRDF provides a comprehensive CLI for RDF store management and project initialization.

### `unrdf init` - Initialize Project Structure

Initialize a new UNRDF project with automatic stack detection and structure analysis.

```bash
# Initialize current directory
npx unrdf init

# Initialize specific path
npx unrdf init --root /path/to/project

# Dry run (preview without applying)
npx unrdf init --dry-run

# Verbose output
npx unrdf init --verbose

# Skip baseline snapshot
npx unrdf init --skip-snapshot

# Skip hook registration
npx unrdf init --skip-hooks
```

**What it does:**
- Scans project file system
- Detects tech stack (frameworks, languages)
- Builds domain model from code
- Classifies file roles (api, component, test, etc.)
- Creates baseline snapshot
- Registers project hooks

**Output:** Comprehensive initialization report with:
- Tech stack profile
- Feature count and roles
- Domain entities
- File statistics
- Test coverage

---

### `unrdf store backup` - Backup RDF Store

Create compressed backups of RDF stores with incremental support.

```bash
# Basic backup
npx unrdf store backup ./my-store

# Custom output path
npx unrdf store backup ./my-store --output backup.tar.gz

# Incremental backup
npx unrdf store backup ./my-store --incremental

# Uncompressed backup
npx unrdf store backup ./my-store --compress false
```

**What it does:**
- Creates compressed archive of RDF store
- Supports incremental backups
- Tracks quad count and graph count
- Measures backup size and duration
- Full OpenTelemetry instrumentation

**Output Example:**
```
‚úÖ Backup completed successfully
üì¶ Backup file: backup-1701234567890.tar.gz
üìä Size: 2.45 MB
üî¢ Quads backed up: 125430
üìà Graphs: 5
‚è±Ô∏è  Duration: 350ms
```

---

### `unrdf store restore` - Restore from Backup

Restore RDF stores from backup archives with validation.

```bash
# Basic restore
npx unrdf store restore backup.tar.gz --target ./restored-store

# Overwrite existing store
npx unrdf store restore backup.tar.gz --target ./my-store --overwrite

# Skip validation
npx unrdf store restore backup.tar.gz --target ./my-store --validate false
```

**What it does:**
- Extracts and validates backup archive
- Restores quads to target store
- Validates backup integrity
- Full OpenTelemetry instrumentation

**Output Example:**
```
‚úÖ Restore completed successfully
üìÇ Store path: ./restored-store
üî¢ Quads restored: 125430
üìà Graphs restored: 5
‚è±Ô∏è  Duration: 280ms
```

---

### `unrdf store import` - Bulk Import RDF Files

Import multiple RDF files into a store with format detection and error handling.

```bash
# Import single file
npx unrdf store import data.ttl --storePath ./my-store

# Import multiple files with glob
npx unrdf store import 'data/*.ttl' --storePath ./my-store

# Specify format explicitly
npx unrdf store import data.nq --storePath ./my-store --format n-quads

# Import to named graph
npx unrdf store import data.ttl --storePath ./my-store --graph http://example.org/graph1

# Continue on errors
npx unrdf store import 'data/*.ttl' --storePath ./my-store --skipErrors
```

**Supported Formats:**
- Turtle (`.ttl`)
- N-Quads (`.nq`)
- N-Triples (`.nt`)
- JSON-LD (`.jsonld`)
- Auto-detection (default)

**What it does:**
- Expands glob patterns to file lists
- Auto-detects RDF format from extension
- Filters directories (imports files only)
- Parses and imports quads to store
- Tracks import statistics
- Full OpenTelemetry instrumentation

**Output Example:**
```
üì• Importing 3 files into ./my-store...
  Processing data/users.ttl...
    ‚úÖ Imported 50 quads
  Processing data/products.ttl...
    ‚úÖ Imported 120 quads
  Processing data/orders.ttl...
    ‚úÖ Imported 85 quads
‚úÖ Import completed successfully
üìÇ Store path: ./my-store
üìÑ Files imported: 3/3
üî¢ Quads imported: 255
üìà Graphs: 2
‚è±Ô∏è  Duration: 125ms
```

---

### Command Status

| Command | Status | Completion | Use Case |
|---------|--------|------------|----------|
| `unrdf init` | ‚úÖ Working | 90/100 | Project initialization and analysis |
| `unrdf store backup` | ‚úÖ Working | 95/100 | Create RDF store backups |
| `unrdf store restore` | ‚úÖ Working | 95/100 | Restore stores from backup |
| `unrdf store import` | ‚úÖ Working | 95/100 | Bulk import RDF files |

**Overall CLI Functionality: 93.75/100** (4/4 commands fully operational)

**Note:** MAPEK autonomic loop functionality is available via programmatic API only. See [Tutorial: Running Your First MAPEK Cycle](#tutorial-2-running-your-first-mapek-cycle) and [V5 Migration Guide](./docs/V5-MIGRATION-GUIDE.md) for details.

## Quick Verification

```javascript
import { createDarkMatterCore, parseTurtle } from 'unrdf';

const system = await createDarkMatterCore();
const store = await parseTurtle('@prefix ex: <http://example.org/> . ex:test ex:works true .');

const results = await system.query({
  query: 'ASK { ?s ?p true }',
  type: 'sparql-ask'
});

console.assert(results === true, 'Basic capability verification');
await system.cleanup();
```

## Links & Resources

- **Repository**: https://github.com/unrdf/unrdf
- **npm**: https://www.npmjs.com/package/unrdf
- **Issues**: https://github.com/unrdf/unrdf/issues
- **Documentation**: [docs/](./docs/)
- **MAPEK Guide**: [docs/AUTONOMIC-MAPEK-README.md](./docs/AUTONOMIC-MAPEK-README.md)
- **Knowledge Hooks Guide**: [docs/guides/knowledge-hooks.md](./docs/guides/knowledge-hooks.md)
- **API Reference**: [docs/reference/api-reference.md](./docs/reference/api-reference.md)

## License

MIT License - see [LICENSE](LICENSE)

---

```json
{
  "@type": "unrdf:ManifestFooter",
  "generatedAt": "2024-01-01T00:00:00Z",
  "validUntil": "2025-12-31T23:59:59Z",
  "verificationHash": "sha256:computed-at-build-time",
  "humanReadable": true,
  "machineReadable": true,
  "formallyVerifiable": true,
  "performanceCharacterized": true,
  "distributionAware": true
}
```
