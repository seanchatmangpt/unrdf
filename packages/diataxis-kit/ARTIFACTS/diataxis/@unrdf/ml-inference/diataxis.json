{
  "confidence": {
    "explanation": 0.7,
    "howtos": 0.75,
    "reference": 0.7,
    "tutorials": 1
  },
  "evidence": {
    "docsFiles": [],
    "examplesFiles": [
      "inference-demo.mjs",
      "standalone-demo.mjs"
    ],
    "fingerprint": "a80b5e044defe2a6d5c0e64ab4d493b068b3e9a2a2ee200b0af56eef0989b10e",
    "readmeHeadings": [
      "Features",
      "Installation",
      "Quick Start",
      "Architecture",
      "Performance",
      "API Reference",
      "Examples",
      "Testing",
      "Performance Tuning",
      "License"
    ]
  },
  "explanation": {
    "architecture": "High-performance machine learning inference pipeline for RDF streams using ONNX Runtime.",
    "concepts": [
      "rdf",
      "ml",
      "onnx",
      "inference",
      "streaming"
    ],
    "confidenceScore": 0.7,
    "id": "explanation-unrdf-ml-inference-explanation",
    "source": [
      "keywords",
      "readme",
      "inferred"
    ],
    "title": "Understanding @unrdf/ml-inference",
    "tradeoffs": [
      "Ease of use vs. advanced configuration options",
      "Memory usage vs. processing speed",
      "Bundle size vs. feature completeness"
    ]
  },
  "generatedAt": "2000-01-01T00:00:00.000Z",
  "howtos": [
    {
      "confidenceScore": 0.5,
      "context": "When you need robust error handling in production",
      "id": "howto-handle-errors",
      "source": [
        "tests"
      ],
      "steps": [
        "Set up try-catch blocks",
        "Handle common error types",
        "Log errors appropriately"
      ],
      "task": "Implement error handling for @unrdf/ml-inference",
      "title": "Handle Errors"
    },
    {
      "confidenceScore": 0.7,
      "context": "When working with rdf in your project",
      "id": "howto-integrate-with-rdf",
      "source": [
        "keywords",
        "inferred"
      ],
      "steps": [
        "Install dependencies",
        "Set up integration",
        "Test integration"
      ],
      "task": "Connect @unrdf/ml-inference with rdf",
      "title": "Integrate with rdf"
    }
  ],
  "packageName": "@unrdf/ml-inference",
  "reference": {
    "confidenceScore": 1,
    "id": "reference-unrdf-ml-inference-reference",
    "items": [
      {
        "description": "Export: ./pipeline",
        "example": "import from \"./src/pipeline/streaming-inference.mjs\"",
        "name": "./pipeline",
        "type": "export"
      },
      {
        "description": "Export: ./registry",
        "example": "import from \"./src/registry/model-registry.mjs\"",
        "name": "./registry",
        "type": "export"
      },
      {
        "description": "Export: ./runtime",
        "example": "import from \"./src/runtime/onnx-runner.mjs\"",
        "name": "./runtime",
        "type": "export"
      },
      {
        "description": "Export: .",
        "example": "import from \"./src/index.mjs\"",
        "name": "@unrdf/ml-inference",
        "type": "export"
      }
    ],
    "source": [
      "exports"
    ],
    "title": "@unrdf/ml-inference Reference"
  },
  "tutorials": [
    {
      "confidenceScore": 0.9999999999999999,
      "goal": "Learn how to set up and use @unrdf/ml-inference in your project",
      "id": "tutorial-getting-started-with-unrdf-ml-inference",
      "prerequisites": [
        "Basic RDF knowledge"
      ],
      "source": [
        "examples",
        "readme",
        "keywords"
      ],
      "stepsOutline": [
        "Install the package",
        "Import required modules",
        "Create a basic example",
        "Run and verify output"
      ],
      "title": "Getting Started with @unrdf/ml-inference"
    }
  ],
  "version": "5.0.1"
}