# @unrdf/daemon Service Level Objectives (SLOs)

Complete Service Level Objectives specification for production daemon operations.

**Version**: 1.0.0
**Last Updated**: 2026-01-10
**Audience**: DevOps, SRE, Engineering Leadership

---

## What Are These SLOs?

Service Level Objectives (SLOs) define the performance expectations for @unrdf/daemon in production. They answer the question: **"What does users/operators experience when everything is working as designed?"**

These SLOs are derived from 6 core JTBD (Jobs To Be Done) scenarios that represent real-world usage patterns:

| # | JTBD | What Users Need | SLO Target | Status |
|---|---|---|---|---|
| **1** | Receipt Generation | Fast audit trail creation | <100ms P99 latency | âœ… Achievable |
| **2** | Verification | Rapid fraud detection | <300s P99 latency | âœ… Achievable |
| **3** | Failover Recovery | Service continuity | <45s recovery, 0 data loss | âš ï¸ Constrained |
| **4** | Diagnostics | Quick troubleshooting | <30s full report | âœ… Achievable |
| **5** | Throughput | Batch processing | 33+ ops/sec @ 1000 concurrent | âš ï¸ Constrained |
| **6** | Deployment | Rapid iteration | <6 minutes end-to-end | âœ… Achievable |

---

## Documents in This Suite

### 1. **slo-definitions.md** (720 lines)
**Comprehensive SLO specification with technical details**

Contains:
- âœ… Detailed SLO statements for all 6 JTBDs
- âœ… Key metrics (units, targets, thresholds)
- âœ… Business impact of missing each SLO
- âœ… Measurement methods (test scenarios)
- âœ… Alert thresholds (severity levels)
- âœ… Performance targets by operation type
- âœ… Risk assessment matrix (RPN analysis)
- âœ… Implementation roadmap (4 phases)
- âœ… Quarterly review process

**Use this for**: Understanding what each SLO means, why it matters, and how to measure it.

**Read time**: 25-30 minutes (technical deep-dive)

---

### 2. **slo-tracking-sheet.csv** (40 metrics)
**Quick-reference metrics tracking spreadsheet**

Contains:
- âœ… All 40 metrics across 6 JTBDs
- âœ… Target values + threshold ranges
- âœ… Alert conditions (when to escalate)
- âœ… Monthly compliance tracking
- âœ… Metric ownership assignments

**Use this for**: Dashboards, reporting, compliance tracking.

**Format**: CSV (import to Excel, Datadog, etc.)

---

### 3. **slo-constraint-analysis.md** (350 lines)
**Deep-dive into WHY SLOs are hard to meet and what trade-offs exist**

Contains:
- âœ… Ranked difficulty (EXTREME â†’ EASY)
- âœ… Physical constraints (immovable limits)
- âœ… Network constraints (Raft consensus delays)
- âœ… Cryptographic constraints (algorithm limits)
- âœ… I/O constraints (disk, CPU bottlenecks)
- âœ… Configuration trade-off matrices
- âœ… Timeline analysis for different scenarios
- âœ… Risk scorecard (15% breach probability for JTBD-5)
- âœ… Quarterly commitment (actionable roadmap)

**Use this for**: Understanding constraints, making architecture decisions, prioritizing optimization work.

**Read time**: 15-20 minutes (executive + technical)

**Key Insight**:
> JTBD-5 (throughput) and JTBD-3 (failover) are your pressure points. Everything else is achievable with standard optimization. Horizontal scaling (2-node cluster) solves both.

---

### 4. **slo-monitoring-guide.md** (791 lines)
**Technical guide for monitoring, dashboards, and alerting**

Contains:
- âœ… Prometheus metric specifications (40+ metrics)
- âœ… Grafana dashboard panel queries
- âœ… AlertManager rule configurations (YAML)
- âœ… Dashboard layout templates
- âœ… Troubleshooting guide (common issues)
- âœ… SLA reporting template
- âœ… Implementation checklist

**Use this for**: Setting up production monitoring, creating dashboards, defining alerts.

**Read time**: 20-25 minutes (DevOps/SRE)

---

## Quick Start: How to Use These SLOs

### For DevOps/SRE Teams

1. **This Week**: Review `slo-definitions.md` (sections 1, 5, 6 for highest impact)
2. **This Week**: Import `slo-tracking-sheet.csv` into your monitoring system
3. **Next Week**: Implement alerts using `slo-monitoring-guide.md`
4. **Monthly**: Generate SLO compliance report (template in monitoring guide)

**Expected effort**: 3-4 days to full production monitoring

---

### For Engineering Teams

1. **This Sprint**: Read `slo-constraint-analysis.md` (understand your constraints)
2. **This Sprint**: Identify which SLOs are your priority (use risk scorecard)
3. **Next Sprint**: Implement optimizations (receipt batching, failover tuning)
4. **Quarterly**: Review actual vs target compliance, adjust work

**Expected effort**: 2 sprints to optimize critical path (JTBD-5, JTBD-3)

---

### For Leadership/Product

1. **Quick Read** (5 min): Review summary table above
2. **Decision**: Do you accept the trade-offs? (e.g., JTBD-5 requires 2-node cluster)
3. **Commitment**: Allocate resources for Q1 optimization (estimated 3-4 weeks eng time)
4. **Review**: Quarterly SLO compliance reporting

---

## SLO Status Summary

### Current Estimated Compliance (Before Optimization)

```
JTBD-1: Receipt Generation    âœ… 99.97%  (exceeds 99.95% target)
JTBD-2: Verification          âœ… 99.91%  (exceeds 99.9% target)
JTBD-3: Failover Recovery     âš ï¸ 98.5%   (misses 99.99% target by 1.5%)
JTBD-4: Diagnostics           âœ… 99.8%   (exceeds 100% target)
JTBD-5: Throughput            âŒ 85%     (misses 95%+ target significantly)
JTBD-6: Deployment            âœ… 88%     (approaching 95%+ target)

Overall:  91.3% / 95% target = Gap of -3.7%
```

### What Needs Work

| Priority | JTBD | Current | Target | Gap | Effort |
|---|---|---|---|---|---|
| ðŸ”´ **CRITICAL** | JTBD-5 | 85% | 95% | -10% | 2-3 weeks |
| ðŸ”´ **CRITICAL** | JTBD-3 | 98.5% | 99.99% | -1.5% | 1-2 weeks |
| ðŸŸ¡ **IMPORTANT** | JTBD-6 | 88% | 95% | -7% | 1-2 weeks |
| ðŸŸ¢ **MONITOR** | JTBD-1,2,4 | >99% | >99% | âœ… | Monitoring only |

---

## Key Metrics at a Glance

### JTBD-1: Receipt Generation Latency
- **Target**: P99 < 45ms, Success rate 99.95%
- **Status**: âœ… Meets target
- **Action**: Monitor, no optimization needed

### JTBD-2: Verification Latency
- **Target**: P99 < 120s, False positive/negative < 0.001%
- **Status**: âœ… Meets target
- **Action**: Security audit + code review

### JTBD-3: Failover Recovery
- **Target**: <45s recovery, 0 bytes data loss, 99.99% success
- **Status**: âš ï¸ Marginal (98.5%)
- **Action**: Tune Raft params, collocate nodes, horizontal scaling
- **Constraint**: Network latency (50-100ms RTT = +50s recovery)

### JTBD-4: Diagnostics
- **Target**: Health check <50ms, full report <30s
- **Status**: âœ… Easily meets target
- **Action**: Monitor, no optimization needed

### JTBD-5: Throughput
- **Target**: 33+ ops/sec with 1000 concurrent, P99 queue wait <500ms
- **Status**: âŒ Under-performing (28 ops/sec current)
- **Action**: Horizontal scaling (2-3 node cluster)
- **Constraint**: CPU cores (10-16 needed for single node, 2-node cluster more practical)

### JTBD-6: Deployment
- **Target**: <360s total time, 99.5% success
- **Status**: âš ï¸ Near target (88%)
- **Action**: npm cache persistence, parallel test execution
- **Constraint**: npm install dominates (40-60% of time)

---

## Implementation Timeline

### Phase 1 (Weeks 1-2): Monitoring
- [ ] Implement OpenTelemetry instrumentation
- [ ] Deploy Prometheus + Grafana
- [ ] Configure AlertManager
- [ ] Establish baseline metrics
- **Result**: Know where you stand

### Phase 2 (Weeks 3-4): Critical Path
- [ ] Optimize JTBD-5 (horizontal scaling)
- [ ] Tune JTBD-3 (Raft parameters)
- [ ] Validate improvements
- **Result**: Hit 95%+ compliance on top 2 pressure points

### Phase 3 (Weeks 5-6): Secondary Optimizations
- [ ] Receipt generation batching (JTBD-1)
- [ ] Deployment pipeline optimization (JTBD-6)
- **Result**: 99%+ compliance across all 6 SLOs

### Phase 4 (Weeks 7+): Hardening
- [ ] Chaos engineering tests
- [ ] Network condition simulation
- [ ] Quarterly compliance reporting
- **Result**: Sustained, measurable SLO compliance

---

## Making Decisions Based on SLOs

### "Should we implement this feature?"

**Ask**: Does this feature impact any of the 6 JTBDs?

- **Yes**: Measure baseline, implement feature, verify SLO still met
- **No**: Implement freely (no SLO impact)

### "Do we have a performance problem?"

**Check**: Which SLOs are you breaching?

- **JTBD-5 breaching**: You're CPU-constrained, need horizontal scaling
- **JTBD-3 breaching**: Network latency is your enemy, collocate or tune Raft
- **JTBD-1 breaching**: I/O bound, enable async writes
- **JTBD-6 breaching**: CI/CD is slow, parallelize tests or cache deps

### "Can we ship this deployment?"

**Check**:
```
Is the feature deployed successfully? âœ… (JTBD-6 < 6 min)
Are all SLO tests passing? âœ… (JTBD 1-5)
â†’ Safe to ship

Is JTBD-3 compliance < 98%? âš ï¸
â†’ Hold, investigate failover first
```

---

## FAQ

### Q: What if we can't meet JTBD-5 (33 ops/sec)?
**A**: Horizontal scaling to 2-3 nodes solves this. Single node has fundamental CPU limits. **This is not a code problem, it's a deployment problem.** Plan for multi-node from day 1.

### Q: What's the cost of meeting these SLOs?
**A**:
- 2-node cluster (JTBD-5): +$500/month
- Extra monitoring (Datadog/Prometheus): +$200/month
- Engineering effort (tuning): ~3 weeks one-time
- Total: Achievable within most budgets

### Q: Which SLO is most critical?
**A**: **JTBD-5 (throughput)**. If batch jobs can't run fast enough, users stop using the daemon. Everything else is optimization.

### Q: Do we need a failover cluster from day 1?
**A**: Not for MVP. Single node works fine for dev/testing. But for production >10K ops/day, you need failover (JTBD-3) + extra capacity (JTBD-5). Plan for 2+ nodes from your first production deployment.

### Q: How often should we review SLOs?
**A**: Monthly compliance report (pass/fail), quarterly deep-dive (why did we miss?), annual refresh (do SLOs still make sense?).

---

## Document Cross-References

| Question | Document | Section |
|---|---|---|
| "What does JTBD-5 mean?" | slo-definitions.md | JTBD 5 |
| "Why is JTBD-3 hard?" | slo-constraint-analysis.md | Consensus Constraints |
| "How do I measure JTBD-1?" | slo-definitions.md | Measurement Method |
| "What alerts do I need?" | slo-monitoring-guide.md | Alert Rules (YAML) |
| "How do I create dashboards?" | slo-monitoring-guide.md | Dashboard Panels |
| "What's my breach probability?" | slo-constraint-analysis.md | Risk Scorecard |
| "Which JTBD should I optimize first?" | slo-constraint-analysis.md | Summary: Where to Focus |
| "What are the trade-offs?" | slo-constraint-analysis.md | Configuration Trade-offs |

---

## Getting Help

**For understanding what SLOs mean**: Read `slo-definitions.md`

**For deciding what to optimize**: Read `slo-constraint-analysis.md`

**For setting up monitoring**: Read `slo-monitoring-guide.md`

**For quick reference**: Use `slo-tracking-sheet.csv`

---

## Success Criteria

You will know you've successfully implemented these SLOs when:

âœ… All 6 JTBDs have automated monitoring dashboards
âœ… Alerts fire (and wake you up) when SLOs breach
âœ… Monthly compliance report shows 95%+ across all 6 JTBDs
âœ… Teams reference SLOs in architecture/optimization discussions
âœ… New features are validated against SLO impact
âœ… Production incidents are understood through SLO metrics

**Expected Timeline**: 4-6 weeks from start to full compliance

---

## Version History

| Version | Date | Changes |
|---|---|---|
| 1.0.0 | 2026-01-10 | Initial specification |
| TBD | TBD | Q1 2026 review + adjustments |

---

**Next Step**: Start with `slo-definitions.md` â†’ read carefully â†’ plan Phase 1 monitoring implementation.

Good luck! ðŸš€

