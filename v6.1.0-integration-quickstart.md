# v6.1.0 Integration Quick-Start Guide

**Target Release**: v6.1.0 (Q1 2026)
**Total Effort**: 17-22 days (parallelizable)
**Priority**: Top 5 high-impact, high-feasibility integrations

---

## Priority 1: Event-Driven Automation (Daemon + V6-Core + Hooks)

**Effort**: 2-3 days | **Potential Score**: 80/100 | **Risk**: LOW

### Files to Create

```
packages/daemon/src/integrations/
├── v6-deltagate-adapter.mjs          # 120 LoC - Main integration
└── v6-deltagate-adapter.test.mjs     # 180 LoC - Tests (8 unit, 3 integration)

packages/v6-core/src/integrations/
└── daemon-listener.mjs               # 80 LoC - Reverse integration
```

### Implementation Sketch

```javascript
// packages/daemon/src/integrations/v6-deltagate-adapter.mjs

import { Daemon } from '../daemon.mjs';
import { DeltaGate } from '@unrdf/v6-core/deltagate';
import { HookRegistry } from '@unrdf/hooks';

/**
 * Event-driven ΔGate automation - daemon monitors deltas and triggers hooks
 * @param {Object} config
 * @param {DeltaGate} config.gate - V6 ΔGate instance
 * @param {HookRegistry} config.hooks - Hook registry
 * @param {Object} config.errorHandling - Retry/backoff config
 */
export function createDeltaGateDaemon(config) {
  const daemon = new Daemon();
  const { gate, hooks, errorHandling = { retry: 3, backoff: 'exponential' } } = config;

  // Listen for deltas
  daemon.listen('deltagate', {
    interval: 100, // Poll every 100ms
    check: async () => {
      const deltas = await gate.getPendingDeltas();
      return deltas.length > 0;
    },
    action: async () => {
      const deltas = await gate.getPendingDeltas();

      for (const delta of deltas) {
        try {
          // Process delta through ΔGate (generates receipt)
          const result = await gate.process(delta);

          // Trigger hooks with delta + receipt
          await hooks.trigger('delta-processed', {
            delta,
            receipt: result.receipt,
            timestamp: Date.now()
          });
        } catch (error) {
          await handleError(error, delta, errorHandling);
        }
      }
    }
  });

  return daemon;
}

async function handleError(error, delta, config) {
  let attempts = 0;
  while (attempts < config.retry) {
    await sleep(Math.pow(2, attempts) * 1000); // Exponential backoff
    try {
      // Retry processing
      await gate.process(delta);
      return;
    } catch (retryError) {
      attempts++;
    }
  }

  // Dead letter queue after exhausting retries
  await gate.moveToDLQ(delta, error);
}
```

### Tests to Write

```javascript
// packages/daemon/src/integrations/v6-deltagate-adapter.test.mjs

describe('DeltaGate Daemon', () => {
  it('should process pending deltas and trigger hooks', async () => {
    const gate = createMockDeltaGate([delta1, delta2]);
    const hooks = createMockHookRegistry();
    const daemon = createDeltaGateDaemon({ gate, hooks });

    await daemon.start();
    await sleep(500);

    expect(hooks.trigger).toHaveBeenCalledWith('delta-processed', expect.objectContaining({
      delta: delta1,
      receipt: expect.any(Object)
    }));
  });

  it('should retry on failure with exponential backoff', async () => { /* ... */ });
  it('should move to DLQ after max retries', async () => { /* ... */ });
});
```

### Documentation

- **Tutorial**: `docs/diataxis/tutorials/event-driven-deltagate.md`
- **How-To**: `docs/diataxis/how-to/daemon-deltagate-setup.md`
- **Example**: `examples/daemon-deltagate-automation.mjs`

---

## Priority 2: Temporal Knowledge Discovery (Semantic-Search + Graph-Analytics + KGC-4D)

**Effort**: 5-7 days | **Potential Score**: 72/100 | **Risk**: MEDIUM

### Files to Create

```
packages/graph-analytics/src/temporal/
├── temporal-pagerank.mjs             # 280 LoC - Time-sliced PageRank
└── temporal-pagerank.test.mjs        # 200 LoC - Tests

packages/semantic-search/src/temporal/
├── time-sliced-search.mjs            # 220 LoC - Temporal semantic search
└── time-sliced-search.test.mjs       # 180 LoC - Tests

packages/graph-analytics/src/
└── temporal-analytics.mjs            # 180 LoC - Unified API
```

### Implementation Sketch

```javascript
// packages/graph-analytics/src/temporal/temporal-pagerank.mjs

import { PageRankAnalyzer } from '../centrality/pagerank-analyzer.mjs';
import { KGCStore } from '@unrdf/kgc-4d';

/**
 * Compute PageRank across time slices to detect emerging concepts
 */
export class TemporalPageRank {
  constructor(kgcStore) {
    this.kgc = kgcStore;
    this.analyzer = new PageRankAnalyzer();
  }

  /**
   * Find concepts with increasing PageRank over time
   * @param {Object} timeRange - { start: ISO8601, end: ISO8601, interval: ms }
   * @returns {Array<{ uri: string, rankChange: number, timestamps: Array }>}
   */
  async detectEmergingConcepts(timeRange) {
    const { start, end, interval } = timeRange;
    const snapshots = [];

    // Time-slice and compute PageRank for each
    for (let t = new Date(start); t <= new Date(end); t = new Date(t.getTime() + interval)) {
      const snapshot = await this.kgc.freezeUniverse(t.toISOString());
      const ranks = await this.analyzer.pagerank(snapshot);
      snapshots.push({ timestamp: t, ranks });
    }

    // Detect concepts with increasing rank
    const firstRanks = snapshots[0].ranks;
    const lastRanks = snapshots[snapshots.length - 1].ranks;

    const emerging = Object.keys(lastRanks)
      .map(uri => ({
        uri,
        rankChange: (lastRanks[uri] || 0) - (firstRanks[uri] || 0),
        rankHistory: snapshots.map(s => ({ time: s.timestamp, rank: s.ranks[uri] || 0 }))
      }))
      .filter(c => c.rankChange > 0.1) // Significant increase
      .sort((a, b) => b.rankChange - a.rankChange);

    return emerging;
  }

  /**
   * Compute PageRank trajectory for a specific concept
   */
  async getConceptTrajectory(uri, timeRange) {
    const { start, end, interval } = timeRange;
    const trajectory = [];

    for (let t = new Date(start); t <= new Date(end); t = new Date(t.getTime() + interval)) {
      const snapshot = await this.kgc.freezeUniverse(t.toISOString());
      const ranks = await this.analyzer.pagerank(snapshot);
      trajectory.push({ timestamp: t, rank: ranks[uri] || 0 });
    }

    return trajectory;
  }
}
```

```javascript
// packages/semantic-search/src/temporal/time-sliced-search.mjs

import { SemanticSearch } from '../search/index.mjs';
import { KGCStore } from '@unrdf/kgc-4d';

export class TemporalSemanticSearch {
  constructor(kgcStore) {
    this.kgc = kgcStore;
    this.search = new SemanticSearch();
  }

  /**
   * Search across time with semantic similarity
   * @param {string} query - Natural language query
   * @param {Object} timeRange - { start, end, interval }
   * @returns {Array<{ timestamp, results }>}
   */
  async temporalQuery(query, timeRange) {
    const { start, end, interval } = timeRange;
    const results = [];

    for (let t = new Date(start); t <= new Date(end); t = new Date(t.getTime() + interval)) {
      const snapshot = await this.kgc.freezeUniverse(t.toISOString());
      const matches = await this.search.query(query, { store: snapshot, limit: 10 });

      results.push({
        timestamp: t.toISOString(),
        matches: matches.map(m => ({
          uri: m.uri,
          score: m.score,
          excerpt: m.excerpt
        }))
      });
    }

    return results;
  }

  /**
   * Detect semantic drift - how query meaning changed over time
   */
  async detectSemanticDrift(query, timeRange) {
    const temporal = await this.temporalQuery(query, timeRange);

    // Compute semantic similarity between time slices
    const drift = [];
    for (let i = 1; i < temporal.length; i++) {
      const prev = temporal[i - 1].matches.map(m => m.uri);
      const curr = temporal[i].matches.map(m => m.uri);

      const intersection = prev.filter(uri => curr.includes(uri));
      const similarity = intersection.length / Math.max(prev.length, curr.length);

      drift.push({
        from: temporal[i - 1].timestamp,
        to: temporal[i].timestamp,
        similarity,
        driftScore: 1 - similarity
      });
    }

    return drift;
  }
}
```

### Tests

```javascript
describe('TemporalPageRank', () => {
  it('should detect emerging concepts with increasing PageRank', async () => {
    const kgc = createMockKGC([snapshot2023, snapshot2024, snapshot2025]);
    const temporal = new TemporalPageRank(kgc);

    const emerging = await temporal.detectEmergingConcepts({
      start: '2023-01-01',
      end: '2025-12-31',
      interval: 365 * 24 * 60 * 60 * 1000 // Yearly
    });

    expect(emerging[0]).toMatchObject({
      uri: 'http://example.org/ai',
      rankChange: expect.any(Number),
      rankHistory: expect.arrayContaining([
        { time: expect.any(Date), rank: expect.any(Number) }
      ])
    });
  });
});
```

### Documentation

- **Tutorial**: `docs/diataxis/tutorials/temporal-knowledge-discovery.md`
- **Example**: `examples/temporal-analytics-demo.mjs`

---

## Priority 3: Template Automation (KGN + Receipts + Daemon)

**Effort**: 3 days | **Potential Score**: 63/100 | **Risk**: LOW

### Files to Create

```
packages/kgn/src/integrations/
├── receipt-renderer.mjs              # 150 LoC - Template rendering with receipts
└── receipt-renderer.test.mjs         # 120 LoC - Tests

packages/daemon/src/tasks/
└── template-watch.mjs                # 100 LoC - File watching for templates
```

### Implementation Sketch

```javascript
// packages/kgn/src/integrations/receipt-renderer.mjs

import { render } from '../renderer/index.js';
import { BatchReceiptGenerator } from '@unrdf/receipts';
import { sha256 } from 'hash-wasm';

/**
 * Render template with cryptographic receipt
 */
export async function renderWithReceipt(template, context, options = {}) {
  // Render template
  const output = await render(template, context);

  // Generate receipt
  const inputHash = await sha256(JSON.stringify({ template, context }));
  const outputHash = await sha256(output);

  const receipt = BatchReceiptGenerator.create({
    operation: 'template-render',
    entityType: 'Template',
    metadata: {
      template,
      inputHash,
      outputHash,
      timestamp: Date.now(),
      ...options.metadata
    }
  });

  return { output, receipt };
}

/**
 * Schedule template re-rendering via daemon
 */
export function scheduleTemplateRendering(daemon, config) {
  const { template, context, trigger, onRender } = config;

  daemon.schedule({
    name: `template-${template}`,
    trigger: trigger || { type: 'file-change', path: template },
    action: async () => {
      const result = await renderWithReceipt(template, context);
      await onRender(result);
      return result.receipt;
    }
  });
}
```

### Documentation

- **How-To**: `docs/diataxis/how-to/template-automation-receipts.md`
- **Example**: `examples/kgn-daemon-automation.mjs`

---

## Priority 4: ML Lineage (Blockchain + Receipts + ML-Versioning)

**Effort**: 3-4 days | **Potential Score**: 64/100 | **Risk**: LOW

### Files to Create

```
packages/ml-versioning/src/
├── blockchain-anchoring.mjs          # 180 LoC - Model version anchoring
└── blockchain-anchoring.test.mjs     # 140 LoC - Tests

packages/blockchain/src/adapters/
└── ml-version-adapter.mjs            # 100 LoC - Adapter
```

### Implementation Sketch

```javascript
// packages/ml-versioning/src/blockchain-anchoring.mjs

import { ReceiptAnchorer } from '@unrdf/blockchain';
import { BatchReceiptGenerator } from '@unrdf/receipts';
import { sha256 } from 'hash-wasm';

export class BlockchainMLVersioning {
  constructor(config) {
    this.anchorer = new ReceiptAnchorer(config.blockchain);
  }

  /**
   * Version ML model with blockchain proof
   */
  async versionModel(modelData) {
    const { modelBytes, trainingDataHash, hyperparameters, metrics } = modelData;

    // Hash model
    const modelHash = await sha256(modelBytes);

    // Create receipt
    const receipt = BatchReceiptGenerator.create({
      operation: 'ml-model-version',
      entityType: 'MLModel',
      metadata: {
        modelHash,
        trainingDataHash,
        hyperparameters,
        metrics,
        timestamp: Date.now()
      }
    });

    // Anchor to blockchain
    const proof = await this.anchorer.anchor(receipt);

    return {
      version: receipt.id,
      receipt,
      blockchainProof: proof,
      verificationUrl: `https://etherscan.io/tx/${proof.txHash}`
    };
  }

  /**
   * Verify model provenance
   */
  async verifyModel(modelBytes, receipt) {
    const modelHash = await sha256(modelBytes);

    if (receipt.metadata.modelHash !== modelHash) {
      throw new Error('Model hash mismatch - tampering detected');
    }

    const valid = await this.anchorer.verify(receipt);
    return valid;
  }
}
```

### Documentation

- **Tutorial**: `docs/diataxis/tutorials/ml-model-compliance.md`
- **How-To**: `docs/diataxis/how-to/blockchain-ml-versioning.md`

---

## Priority 5: Live Workflow UI (YAWL-Realtime + React + Observability)

**Effort**: 4-5 days | **Potential Score**: 63/100 | **Risk**: MEDIUM

### Files to Create

```
packages/react/src/hooks/
├── useWorkflow.mjs                   # 180 LoC - React hook
└── useWorkflow.test.mjs              # 140 LoC - Tests

packages/yawl-realtime/src/
├── sse-adapter.mjs                   # 150 LoC - Server-Sent Events
└── sse-adapter.test.mjs              # 100 LoC - Tests

packages/react/src/components/
└── WorkflowViz.jsx                   # 200 LoC - Visualization component
```

### Implementation Sketch

```javascript
// packages/react/src/hooks/useWorkflow.mjs

import { useState, useEffect } from 'react';
import { createTracer } from '@unrdf/observability';

/**
 * React hook for real-time workflow state
 * @param {string} workflowId
 * @param {Object} options
 * @returns {{ state, metrics, error, loading }}
 */
export function useWorkflow(workflowId, options = {}) {
  const [state, setState] = useState(null);
  const [metrics, setMetrics] = useState(null);
  const [error, setError] = useState(null);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    const tracer = createTracer('ui-workflow');
    const span = tracer.startSpan('subscribe-workflow');

    // Server-Sent Events connection
    const eventSource = new EventSource(`/api/workflows/${workflowId}/stream`);

    eventSource.onmessage = (event) => {
      const data = JSON.parse(event.data);

      if (data.type === 'state-update') {
        setState(data.state);
        span.addEvent('state-updated', { state: data.state.status });
      }

      if (data.type === 'metrics-update') {
        setMetrics(data.metrics);
      }

      setLoading(false);
    };

    eventSource.onerror = (err) => {
      setError(err);
      setLoading(false);
      span.recordException(err);
      span.end();
    };

    return () => {
      eventSource.close();
      span.end();
    };
  }, [workflowId]);

  return { state, metrics, error, loading };
}
```

```javascript
// packages/yawl-realtime/src/sse-adapter.mjs

import { WorkflowEngine } from '@unrdf/yawl';
import { createTracer } from '@unrdf/observability';

/**
 * Server-Sent Events adapter for real-time workflow updates
 */
export class SSEWorkflowAdapter {
  constructor(engine) {
    this.engine = engine;
    this.tracer = createTracer('yawl-realtime');
    this.clients = new Map();
  }

  /**
   * Express/Fastify middleware
   */
  handleSSE(req, res) {
    const { workflowId } = req.params;
    const span = this.tracer.startSpan('sse-connection');

    // SSE headers
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');

    // Subscribe to workflow events
    const subscription = this.engine.subscribe(workflowId, (event) => {
      res.write(`data: ${JSON.stringify(event)}\n\n`);
      span.addEvent('event-sent', { type: event.type });
    });

    this.clients.set(req.id, subscription);

    // Cleanup on disconnect
    req.on('close', () => {
      subscription.unsubscribe();
      this.clients.delete(req.id);
      span.end();
    });
  }
}
```

### Documentation

- **Tutorial**: `docs/diataxis/tutorials/react-workflow-dashboard.md`
- **How-To**: `docs/diataxis/how-to/live-workflow-ui-setup.md`
- **Example**: `examples/react-workflow-viz-demo.jsx`

---

## Parallel Development Strategy

### Week 1-2
- **Team A**: Priority 1 (Daemon + V6-Core + Hooks) - 2-3 days
- **Team B**: Priority 3 (KGN + Receipts + Daemon) - 3 days
- **Team C**: Priority 4 (Blockchain + ML-Versioning) - 3-4 days

### Week 2-3
- **Team A**: Priority 5 (YAWL-Realtime + React) - 4-5 days
- **Team B**: Priority 2 (Semantic-Search + Graph-Analytics) - 5-7 days

**Total Calendar Time**: ~3 weeks (with 3 parallel teams)

---

## Quality Gates

### Before Merging Each Integration

- [ ] Unit tests: ≥80% coverage
- [ ] Integration tests: ≥3 end-to-end scenarios
- [ ] Benchmark: Performance baseline established (no regression)
- [ ] OTEL spans: All major operations traced
- [ ] Documentation: Tutorial + How-To + 1 example
- [ ] Code review: 2 approvals from core team
- [ ] Quality score: ≥70/100 (run `pnpm quality`)

### Pre-Release Validation

```bash
# Run full test suite
timeout 30s pnpm test:fast

# Check lint
timeout 30s pnpm lint

# Verify benchmarks
pnpm benchmark:regression

# Generate quality report
pnpm quality:json > v6.1.0-quality.json

# Verify all integrations documented
grep -r "v6.1.0" docs/diataxis/ | wc -l  # Should be ≥15
```

---

## Risk Mitigation

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Temporal analytics too slow | MEDIUM | HIGH | Implement caching layer for time-sliced queries |
| SSE connection instability | LOW | MEDIUM | Add heartbeat + auto-reconnect in useWorkflow |
| Blockchain anchoring cost | LOW | LOW | Use testnet (Goerli) for demos, make production optional |
| Integration test flakiness | MEDIUM | MEDIUM | Use deterministic mocks, avoid real network calls |

---

## Success Metrics (Post-v6.1.0)

- **Adoption**: ≥10 community projects using new integrations within 60 days
- **Performance**: Zero regressions in existing benchmarks
- **Documentation**: ≤3% of GitHub issues asking "how to integrate X with Y"
- **Quality**: Average quality score ≥75/100 across new packages
- **Maintenance**: ≤15% of total issues related to new integrations

---

## Next Steps

1. **Create GitHub Issues**: One issue per priority integration
2. **Assign Teams**: Distribute work based on expertise
3. **Set Up Tracking**: Use GitHub Projects board for progress
4. **Schedule Reviews**: Bi-weekly integration review meetings
5. **Prepare Demos**: One demo per integration for v6.1.0 launch

**Launch Target**: End of Q1 2026
